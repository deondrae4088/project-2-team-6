{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joelfreeman38/project-2-team-6/blob/master/Copy_of_cg_arima.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skpDrX4pzhjB"
      },
      "source": [
        "## Analysis - Housing Price Prediction using Zillow Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "N5mcS9GRzhjE"
      },
      "outputs": [],
      "source": [
        "# Importing what we need\n",
        "import numpy as np\n",
        "e = np.e\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "pd.set_option('display.max_rows', None)\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from pmdarima.arima import auto_arima\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tArNDEBnzhjG"
      },
      "source": [
        "## Read the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Z_n28lokzhjG",
        "outputId": "48ae5b7f-b857-4ddf-aede-1ac32b73aecd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../resources/data/metro_zillow.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-9fd4cb9b2503>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../resources/data/metro_zillow.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Taking a look at the shape of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../resources/data/metro_zillow.csv'"
          ]
        }
      ],
      "source": [
        "# Read the data\n",
        "df = pd.read_csv(\"../resources/data/metro_zillow.csv\", nrows=1000)\n",
        "\n",
        "# Taking a look at the shape of the dataset\n",
        "print(df.shape)\n",
        "\n",
        "# This line will tell us how many of our rows represent metro areas\n",
        "print(df.RegionType.value_counts())\n",
        "\n",
        "# Examining the first five rows of our dataframe\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwd4JK3rzhjH"
      },
      "source": [
        "The raw dataframe contains 928 rows and 87 columns. Among these columns, five provide details about the metro area associated with each row. Columns 6 through 82 represent a time series spanning from March 2018 to December 2024, with values indicating the median home price for that metro area in each specific month.\n",
        "\n",
        "Notably, out of the 928 rows, the last row is unique in that it does not correspond to a specific metro area. Instead, it tracks the median home price for the entire United States."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC31abtqzhjH"
      },
      "source": [
        "## Investing in California\n",
        "* For an investment in California, we need to filter down our dataset to metro areas in CA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDsCLRYvzhjI"
      },
      "outputs": [],
      "source": [
        "# Making a dataframe of just California data\n",
        "df_ca = df[df['StateName'] == 'CA']\n",
        "\n",
        "# Seeing how many rows we get\n",
        "print(df_ca.shape)\n",
        "\n",
        "# Sanity check\n",
        "df_ca.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CDuUZ4zzhjI"
      },
      "source": [
        "* So after filtering our dataframe down, we are left with 34 metro areas throughout California."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTj_1X1MzhjI"
      },
      "source": [
        "## Checking for NaN values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFlJTnlezhjI"
      },
      "outputs": [],
      "source": [
        "# Checking our dataframe for NaN values\n",
        "print(f'There are {df_ca.isna().sum().sum()} NaNs in our original dataframe')\n",
        "\n",
        "# Backfilling that single NaN\n",
        "df_ca.fillna(method='bfill', inplace=True)\n",
        "\n",
        "# Sanity check\n",
        "print(f'There are {df_ca.isna().sum().sum()} NaNs after using backfill')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXyt-hE2zhjJ"
      },
      "outputs": [],
      "source": [
        "#Price distribution within Michigan\n",
        "# Getting a list of the values for the last date in our time series\n",
        "current_median_msa_home_prices = list(df_ca['12/31/2024'])\n",
        "\n",
        "# Plotting the results\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "plt.hist(current_median_msa_home_prices, bins=20)\n",
        "plt.title('2024 CA State Median Home Price by Metro Area')\n",
        "plt.xlabel('Median Home Price')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7jCMRMAzhjJ"
      },
      "source": [
        "* We have a few outliers, some of which are Santa Maria and Salinas area, as confirmed below. However, this doesn't necessarily imply that they are the best or worst investment choice, despite what our models may suggest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6y6G4B0zhjJ"
      },
      "outputs": [],
      "source": [
        "# Checking the median home price for Ann Arbor in the most recent month.\n",
        "int(df_ca[df_ca['RegionName'] == 'Salinas, CA']['12/31/2024'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ygYy2obzhjJ"
      },
      "source": [
        "## Melt Data Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYJPKX5EzhjJ"
      },
      "outputs": [],
      "source": [
        "def melt_data(df):\n",
        "    \"\"\"\n",
        "    Takes the zillow_data dataset in wide form or a subset of the zillow_dataset.\n",
        "    Returns a long-form datetime dataframe\n",
        "    with the datetime column names as the index and the values as the 'values' column.\n",
        "\n",
        "    If more than one row is passes in the wide-form dataset, the values column\n",
        "    will be the mean of the values from the datetime columns in all of the rows.\n",
        "    \"\"\"\n",
        "    melted = pd.melt(df, id_vars=['RegionID', 'SizeRank', 'RegionName', 'RegionType', 'StateName'], var_name='time')\n",
        "    melted['time'] = pd.to_datetime(melted['time'], infer_datetime_format=True)\n",
        "    melted = melted.dropna(subset=['value'])\n",
        "    return melted.groupby('time').aggregate({'value':'mean'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnQkTwPGzhjJ"
      },
      "source": [
        "## Time Series for California"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_OwAMM5zhjJ"
      },
      "outputs": [],
      "source": [
        "# Melting the California dataframe\n",
        "df_ca_melted = melt_data(df_ca)\n",
        "\n",
        "# Plotting the average time series for all of CA state\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "plt.plot(df_ca_melted)\n",
        "plt.title('Averaged Median Home Prices in CA State from 2018 - 2025')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Averaged Median Home Price')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmsQhWCRzhjK"
      },
      "source": [
        "## Reshaping the Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaqRUQwdzhjK"
      },
      "outputs": [],
      "source": [
        "# Reshaping the dataframe\n",
        "df_reshaped = pd.DataFrame()\n",
        "for i in df_ca['RegionName']:\n",
        "    x = melt_data(df_ca[df_ca['RegionName'] == i])\n",
        "    df_reshaped = pd.concat([df_reshaped, x], axis=1)\n",
        "    df_reshaped.rename(columns = {'value':i}, inplace = True)\n",
        "\n",
        "df_reshaped.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2w7qTeLzhjK"
      },
      "source": [
        "# Time Series Length\n",
        "* A key characteristic of our raw dataset must be addressed: Like the rest of the U.S., California experienced a sharp decline in home sales in 2021. If we train our models on the entire dataset, they may be disproportionately influenced pre-2020, sub 3% interest rates, which could impact their predictive accuracy—especially since our business use case focuses on forecasting just one year ahead.\n",
        "\n",
        "* To prevent this from compromising model performance in validation tests and future predictions, we will limit our training data to only include data from March 2018 onward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDJY43s9zhjK"
      },
      "outputs": [],
      "source": [
        "# Reshape to make sure we train our model from Mar 2018 and beyond\n",
        "df_2018 = df_reshaped['2018-03-31':]\n",
        "\n",
        "# Examining the new shape\n",
        "print(df_2018.shape)\n",
        "\n",
        "# Sanity check\n",
        "df_2018.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfLYiMoQzhjK"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9WTZ-EgzhjL"
      },
      "source": [
        "* To validate our models and assess their effectiveness, we need to split our time series data into a training set and a test set. In a time series context, the training set will consist of the first 80% of the data, while the test set will cover the remaining 20%. Since our post-March 2018 data spans 6.92 years, this results in a training period of 5.25 years and a test period of 1.67 years.\n",
        "\n",
        "* This training-to-test ratio strengthens the justification for our predictions. If our models can accurately forecast values 2 years ahead based on 6.92 years of data, we can be more confident in their ability to predict values one year ahead using a larger dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vszt3lAlzhjL"
      },
      "outputs": [],
      "source": [
        "# Printing out the lengths of our unsplit time series\n",
        "print(f'Whole series lengths: {len(df_2018)} \\n')\n",
        "\n",
        "# Manually dividing the data into train and test sets\n",
        "train = df_2018[:'2023-05-31']\n",
        "test = df_2018['2023-05-31':]\n",
        "\n",
        "# Printing the lengths of our new train and test sets\n",
        "print(f'Train set lengths: {len(train)}')\n",
        "print(f'Test set lengths: {len(test)} \\n')\n",
        "\n",
        "# Checking that the proportions are how we want them\n",
        "print(f'Train proportion = {round(len(train) / len(df_2018),1)}')\n",
        "print(f'Test proportion = {round(len(test) / len(df_2018),1)} \\n')\n",
        "\n",
        "# Checking the length in years of our train and test sets\n",
        "print(f'Train set length in years: {round(len(train) / 12, 2)}')\n",
        "print(f'Test set length in years: {round(len(test) / 12, 2)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jTDISDqzhjL"
      },
      "source": [
        "## Setting a Performance Benchmark Before Model Training\n",
        "* To assess whether modeling will provide value in this business context, we will compare our models' performance against a simple, exploratory data analysis approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGXwvOY6zhjL"
      },
      "outputs": [],
      "source": [
        "# Establishing a Performance Baseline Before Modeling\n",
        "# These lists will hold the names of each metro area, as well as that area's ROI from 2012 to 2021\n",
        "names = []\n",
        "historical_roi = []\n",
        "\n",
        "# This for loop adds the information to the two lists\n",
        "for i in range(len(train.columns)):\n",
        "\n",
        "    clean_name = train.columns[i][:-4]\n",
        "\n",
        "    initial_val = train[train.columns[i]]['2018-03-31']\n",
        "    present_val = train[train.columns[i]]['2023-04-30']\n",
        "\n",
        "    roi = round(((present_val - initial_val) / initial_val) * 100, 2)\n",
        "\n",
        "    names.append(clean_name)\n",
        "    historical_roi.append(roi)\n",
        "\n",
        "# Turning the data into a pandas dataframe\n",
        "roi_df = pd.DataFrame()\n",
        "roi_df['City'] = names\n",
        "roi_df['% ROI'] = historical_roi\n",
        "roi_df.sort_values(['% ROI'], inplace=True, ascending=False)\n",
        "roi_df.set_index('City', inplace=True)\n",
        "\n",
        "# Plotting the historical data\n",
        "fig, ax = plt.subplots(figsize=(20,5))\n",
        "plt.bar(roi_df.index, roi_df['% ROI'])\n",
        "plt.title('% ROI by Metro Area 2018 - 2023')\n",
        "plt.xlabel('Metro Area')\n",
        "plt.ylabel('% ROI')\n",
        "plt.xticks(rotation=45)\n",
        "plt.axhline(0, color='k')\n",
        "plt.show()\n",
        "\n",
        "# Displaying our top five choices based on EDA\n",
        "roi_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVL0ao3rzhjL"
      },
      "outputs": [],
      "source": [
        "# Our top five choices based on EDA results\n",
        "top_5 = ['Visalia, CA', 'Yuba City, CA', 'Sonora, CA', 'Crescent City, CA', 'Hanford, CA']\n",
        "\n",
        "# These two lists will track our buy and sell numbers\n",
        "buys = []\n",
        "sells = []\n",
        "\n",
        "# Getting the median values for 2023 (buys) and 2024 (sells)\n",
        "for i in top_5:\n",
        "    buys.append(df_2018[i]['2023-04-30'])\n",
        "    sells.append(df_2018[i]['2024-12-31'])\n",
        "\n",
        "# Calculating the ROI we would have achieved\n",
        "eda_roi = round( ((sum(sells) - sum(buys)) / sum(buys) ) * 100, 2)\n",
        "\n",
        "# Printing the ROI\n",
        "print(f'Using an EDA approach, we could have achieved {eda_roi}% ROI from 2023 to 2024')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-LQbzvyzhjL"
      },
      "source": [
        "## Modeling\n",
        "* Preparing the functions - Since our goal is to identify the five most optimal metro areas for investment within California, we need to run time series models for each metro area individually. Given that there are 34 metro areas, doing this manually is impractical, so we are automating the process by writing functions to handle these steps efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_W1j1xezhjL"
      },
      "outputs": [],
      "source": [
        "def log_transform(series_i):\n",
        "\n",
        "    '''Takes in a series and returns the log transformed version of that series'''\n",
        "\n",
        "    log_transformed = np.log(series_i)\n",
        "    dropped_nans = log_transformed.dropna()\n",
        "    return dropped_nans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0ADrU31zhjM"
      },
      "outputs": [],
      "source": [
        "def run_auto_arima(series_i):\n",
        "\n",
        "    '''ARIMA (Autoregressive Integrated Moving Average) is specifically designed to model time\n",
        "    series data, meaning it analyzes patterns within a sequence of data points ordered by time,\n",
        "    allowing prediction of future values based on past trends.\n",
        "    Runs a grid search on the series passed in, then instantiates and fits\n",
        "    an ARIMA model with those hyperparameters, then returns that fit model. '''\n",
        "    # Function to automatically select and fit SARIMA model\n",
        "def run_auto_sarima(series_i):\n",
        "    \"\"\"Runs a grid search for the best SARIMA model parameters and fits the SARIMA model.\"\"\"\n",
        "    gridsearch = auto_arima(\n",
        "        series_i,\n",
        "        start_p=0, max_p=3,\n",
        "        d=None, max_d=3,\n",
        "        start_q=0, max_q=3,\n",
        "        seasonal=True,\n",
        "        m=12,  # Monthly data seasonality\n",
        "        start_P=0, max_P=3,\n",
        "        start_Q=0, max_Q=3,\n",
        "        max_order=10,\n",
        "        stepwise=True,\n",
        "        suppress_warnings=True\n",
        "    )\n",
        "\n",
        "    model = SARIMAX(\n",
        "        series_i,\n",
        "        order=gridsearch.order,\n",
        "        seasonal_order=gridsearch.seasonal_order,\n",
        "        enforce_stationarity=False,\n",
        "        enforce_invertibility=False\n",
        "    )\n",
        "    return model.fit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dgZFCQ5zhjM"
      },
      "outputs": [],
      "source": [
        "def run_sarima_model(i, steps, df):\n",
        "    \"\"\"Runs SARIMA on the selected time series, returning forecast results.\"\"\"\n",
        "    series = df.iloc[:, i:i+1]\n",
        "    name = series.columns[0]\n",
        "    log_series = np.log(series).dropna()\n",
        "\n",
        "    model = run_auto_sarima(log_series)\n",
        "    log_forecast = model.get_forecast(steps)\n",
        "    forecast_series = np.exp(log_forecast.summary_frame())\n",
        "\n",
        "    return name, series, forecast_series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwOtgW6WzhjM"
      },
      "outputs": [],
      "source": [
        "# Function to plot results\n",
        "def plot_sarima_results(i, steps, df):\n",
        "    name, original_series, forecast_series = run_sarima_model(i, steps, df)\n",
        "\n",
        "    plt.figure(figsize=(15, 7))\n",
        "    plt.plot(original_series, label='Original')\n",
        "    plt.plot(forecast_series['mean'], label='Predicted')\n",
        "    plt.fill_between(\n",
        "        forecast_series.index,\n",
        "        forecast_series['mean_ci_lower'],\n",
        "        forecast_series['mean_ci_upper'],\n",
        "        color='gray', alpha=0.2\n",
        "    )\n",
        "    plt.title(name)\n",
        "    plt.legend()\n",
        "    plt.xlabel('Year')\n",
        "    plt.ylabel('Median Home Price')\n",
        "    plt.show()\n",
        "\n",
        "    forecast = round(forecast_series['mean'][steps - 1])\n",
        "    low_int = round(forecast_series['mean_ci_lower'][steps - 1])\n",
        "    high_int = round(forecast_series['mean_ci_upper'][steps - 1])\n",
        "    print(f\"{steps}-month forecast: {forecast}\")\n",
        "    print(f\"95% confidence interval: {low_int} - {high_int}\")\n",
        "\n",
        "# Example usage (Make sure df_2018 is loaded before running this)\n",
        "# plot_sarima_results(1, 12, df_2018)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6O8t894izhjM"
      },
      "outputs": [],
      "source": [
        "def evaluate_models(df1, df2):\n",
        "\n",
        "    '''This function takes in two dataframes (train and test in our case),\n",
        "    and returns a dataframe with how accurate the models fit to the train\n",
        "    set were in predicting the test set values.'''\n",
        "\n",
        "    names = []\n",
        "    actuals = []\n",
        "    preds = []\n",
        "    perc_errors = []\n",
        "\n",
        "    for i in range(len(train.columns)):\n",
        "\n",
        "        name, series, forecast_series = run_arima_model(i, 24, df1)\n",
        "\n",
        "        clean_name = name[:-4]\n",
        "\n",
        "        actual_val = df2[name][-1]\n",
        "        predicted_val = forecast_series.iloc[23, 0]\n",
        "        error = abs(actual_val - predicted_val)\n",
        "        percent_error = (error/ actual_val) * 100\n",
        "\n",
        "        names.append(clean_name)\n",
        "        actuals.append(f'{round(actual_val):,}')\n",
        "        preds.append(f'{round(predicted_val):,}')\n",
        "        perc_errors.append(round(percent_error, 2))\n",
        "\n",
        "        #print(train.columns[i][:-4], 'done', f'{i+1}/26')\n",
        "\n",
        "\n",
        "    results_df = pd.DataFrame(index=names)\n",
        "    results_df['2024 Actual'] = actuals\n",
        "    results_df['2024 Predicted'] = preds\n",
        "    results_df['% Error'] = perc_errors\n",
        "    results_df.sort_values(by='% Error', inplace=True)\n",
        "\n",
        "    return results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_7xoen8zhjM"
      },
      "outputs": [],
      "source": [
        "def generate_predictions(df, steps):\n",
        "\n",
        "    '''Similar to evaluate_models(), this function takes in a dataframe,\n",
        "    and a specific number of steps, and returns a dataframe of the\n",
        "    future predictions the specified number of steps past the end of\n",
        "    the sample.'''\n",
        "\n",
        "    names = []\n",
        "    current_vals = []\n",
        "    pred_vals = []\n",
        "    net_profits = []\n",
        "    ROI_strings = []\n",
        "\n",
        "    count = 0\n",
        "    for i in range(len(df.columns)):\n",
        "\n",
        "        count += 1\n",
        "\n",
        "        name, series, forecast = run_arima_model(i, steps, df)\n",
        "\n",
        "        clean_name = name[:-4]\n",
        "        print(clean_name)\n",
        "\n",
        "        cur_val = series.iloc[-1, 0]\n",
        "        pred_val = forecast.iloc[steps-1, 0]\n",
        "        net_prof = round(pred_val - cur_val , 2)\n",
        "        roi = int(round(((pred_val - cur_val) / cur_val) * 100, 2))\n",
        "\n",
        "        names.append(clean_name)\n",
        "        current_vals.append(f'{round(cur_val):,}')\n",
        "        pred_vals.append(f'{round(pred_val):,}')\n",
        "        net_profits.append(f'{round(net_prof):,}')\n",
        "        ROI_strings.append(f'{roi}%')\n",
        "\n",
        "        if count == 26:\n",
        "            break\n",
        "\n",
        "\n",
        "    results_df = pd.DataFrame()\n",
        "    results_df['City'] = names\n",
        "    results_df.set_index(['City'])\n",
        "    results_df['Current Value'] = current_vals\n",
        "    results_df['Predicted Value'] = pred_vals\n",
        "    results_df['Net Profit'] = net_profits\n",
        "    results_df['ROI'] = ROI_strings\n",
        "\n",
        "    return results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8EkqsDSzhjN"
      },
      "source": [
        "## Model Evaluation\n",
        "* To ensure our future predictions remain reasonably accurate, we will first assess how well our models perform on existing data. The evaluate_models() function will measure the difference between our model predictions for December 2024 and the actual observed values for that month.\n",
        "\n",
        "* Since the models are trained only on data from 2018 to 2023, their predictions for December 2024 are made without any knowledge of the test data, which spans from 2023 to 2024. This approach helps validate their reliability in forecasting future trends."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ai8jJRkDzhjN"
      },
      "outputs": [],
      "source": [
        "# This dataframe will show us how accurate our models are\n",
        "eval_df = evaluate_models(train, test)\n",
        "\n",
        "# Displaying the dataframe\n",
        "eval_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-QGwvAYzhjN"
      },
      "outputs": [],
      "source": [
        "eval_df = eval_df.iloc[:-1]\n",
        "eval_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ls9_Jfx2zhjN"
      },
      "outputs": [],
      "source": [
        "# Calculating the average error using the dataframe above\n",
        "average_error = str(round(sum([int(i) for i in eval_df['% Error']]) / len(eval_df) , 2)) + '%'\n",
        "\n",
        "# Printing the result\n",
        "print(f\"On average our model based predictions were {average_error} off from the observed values.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kqVwQTXzhjN"
      },
      "source": [
        "* On average, our model's predictions were about 9.21% off from the actual values in our test set. We are satisfied with these validation results, especially since we haven’t manually tuned any of the models.\n",
        "\n",
        "* Moreover, this 9.21% average error comes from models trained on 5 years of data to predict two years ahead. In our final recommendations, we will use ten years of training data to predict just one year ahead. This suggests that our future predictions will likely be even more accurate than those in this validation test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQtjHAIGzhjO"
      },
      "outputs": [],
      "source": [
        "# Getting predictions from our models for December of 2024\n",
        "model_predictions_2024 = generate_predictions(train, 24)\n",
        "\n",
        "# Checking out the results\n",
        "model_predictions_2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5JR1HgXzhjO"
      },
      "outputs": [],
      "source": [
        "# A list of the top five metro areas output by our models\n",
        "model_top_5 = ['Madera, CA', 'Santa Cruz, CA', 'Merced, CA', 'Hanford, CA', 'Stockton, CA']\n",
        "\n",
        "# Variables to track initial and final investment value\n",
        "buys = 0\n",
        "sells = 0\n",
        "\n",
        "# Adding the relevant values\n",
        "for i in model_top_5:\n",
        "    buys  += df_2018[i]['2023-04-30']\n",
        "    sells += df_2018[i]['2024-12-31']\n",
        "\n",
        "# Calculating the ROI\n",
        "model_roi_2023 = round(((sells - buys) / buys) * 100 , 2)\n",
        "\n",
        "# Displaying the results\n",
        "print(f'Using modeling, we could have achieved {model_roi_2023}% ROI from 2023 to 2024')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWcLj9pazhjP"
      },
      "source": [
        "* Switching from an EDA-based approach to modeling would have increased ROI from -0.26 % to -0.18 % between April 2023 and December 2024. This confirms that our modeling efforts are worthwhile and significantly impact this specific business outcome."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OOtq3XMzhjP"
      },
      "source": [
        "## Predictions\n",
        "* The goal of this project is to give potential clients a starting point for investing in California real estate by identifying the five metro areas best suited for short-term investment. We have now reached the stage where we can make these predictions.\n",
        "\n",
        "* Using the same modeling process as before, we will apply our models to the full 2018–2024 dataset to forecast the median home value for each of the 34 metro areas in December 2025. We will then rank these 26 growth estimates by highest projected ROI and select the top five as our final recommendations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gc9yhfOlzhjP"
      },
      "outputs": [],
      "source": [
        "# Generating predictions one year past our entire 2018 to 2024 dataset\n",
        "recommendation_df = generate_predictions(df_2018, 12)\n",
        "\n",
        "# Looking at the results\n",
        "recommendation_df.iloc[1:,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkrW-FdLzhjP"
      },
      "outputs": [],
      "source": [
        "plot_results(1, 12, df_2018)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYyg8B8uzhjP"
      },
      "outputs": [],
      "source": [
        "plot_results(2, 12, df_2018)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuo6fyTjzhjQ"
      },
      "outputs": [],
      "source": [
        "plot_results(4, 12, df_2018)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxircoDUzhjQ"
      },
      "outputs": [],
      "source": [
        "plot_results(6, 12, df_2018)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6eEu7MYzhjQ"
      },
      "outputs": [],
      "source": [
        "plot_results(9, 12, df_2018)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}